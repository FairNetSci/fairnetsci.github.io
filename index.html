<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Thematic Session at NetSci-X 2026</title>
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
  
  <header class="site-header">
    <div class="header-inner">
      <a class="logo" href="#home">NetSci-X 2026</a>
      <button id="menu-toggle" aria-label="Toggle menu">☰</button>
      <nav id="site-nav" class="site-nav">
        <a href="#home">Home</a>
        
        <a href="#call">Call for Abstracts</a>
        
		<a href="#dates">Important Dates</a>
        <a href="#speakers">Speakers</a>
        <a href="#schedule">Program</a>
        <a href="#organizers">Organizers</a>
       <div class="dropdown">
    <button class="dropbtn">Past Editions ▾</button>
    <div class="dropdown-content">
      <a href="2025/index.html" target="_blank">2025</a>
      
    </div>
  </div>
      </nav>
    </div>
  </header>

  <!-- Hero / Home -->
  <main>
    <section id="home" class="hero">
      <div class="hero-inner">
        <h1>Algorithmic Fairness in Network Science</h1>
        <p class="lead">Thematic Session at NetSci-X 2026</p>
		<p>Auckland, New Zealand</p>
        
      </div>
    </section>

    <!-- About -->
    <section id="about" class="section container">
      
      <p>
        The Algorithmic Fairness in Network Science (FairNetSci) thematic session explores the biases and disparities 
		within networks and their implications on algorithmic outcomes. Network inequality refers to the structural biases,
		perception disparities, and persistent inequalities stemming from connection patterns among agents in a network. 
		These biases shape individuals' social views, behavioural decisions, and influence, highlighting the real-world 
		impact of network structures.
      </p>
      <p>
       Algorithms designed without addressing such biases risk producing unfair outcomes, particularly for minority groups.
	   For example, link prediction algorithms may fail to accurately predict connections for smaller or less connected groups
	   due to structural biases. Furthermore, recommendation systems can inadvertently amplify existing inequalities through 
	   their learning processes. However, with thoughtful design, algorithms can mitigate these biases and promote fair outcomes
	   for all individuals and groups, irrespective of their size or type.

      </p>
	  <p>This thematic session aims to bring together experts from diverse fields, including computer science, data science, 
	  social science, mathematics, and network science, to collaboratively explore and address these challenges. 
	  The satellite will feature Keynote, invited, and contributed lightning talks.</p>
	  <p> This satellite event also allows junior researchers to showcase their work, including graduate students, 
	  postdocs, and young professors. A Best Student Paper Award will be presented to the most outstanding submission 
	  led by a graduate student.</p>


    </section>

    <!-- Call for Papers -->
    <section id="call" class="section alt">
      <div class="container">
        <h2>Call for Abstracts</h2>
        <p>
          Join us in the beautiful city of Auckland for the “Algorithmic Fairness in Network Science” thematic session 
		  at the NetSciX-26 event. This session aims to bring together researchers and practitioners from diverse fields
		  to explore inequality in network structures and dynamics, as well as the development of fair and ethical algorithms
		  in network science.

        </p>
		<p>Submissions from junior researchers, including graduate students, postdocs, and pre-tenure faculty, are especially encouraged. 
		The submissions will be accepted for regular talks, lightning talks, and poster presentations.</p>
		<h2> Scope </h2>
		<p>We invite submissions on <b>understanding network inequalities</b> and <b>designing fair algorithms</b> in network science.
		Contributions are welcome on, but not limited to, the following topics:</p>

        <ul class="dot-list">
          <li>Structuring Inequalities in Networks</li>
          <li>Measuring and mitigating biases in network algorithms</li>
          <li>Fairness in SNA methods, such as community detection, link prediction, and influence maximisation</li>
          <li>Disparities in access, visibility, or resources in social and information networks</li>
		  <li>Algorithmic fairness in recommender systems and social network platforms</li>
		  <li>Case studies on the real-world impact of inequalities in networks</li>
		  <li>Ethical considerations in the design and deployment of network algorithms</li>
		  <li>Strategies for ensuring inclusivity and equity in network-driven decision-making</li>
        </ul>
		<p>This session does not have archival proceedings. Submissions may include:</p>
		<ul class="dot-list">
		<li>Recently published works</li>
		<li>Papers under peer review (e.g., arXiv papers)</li>
		<li>Work in progress</li>
		</ul>
		
		
		

        <p class="muted">Submission Round one deadline: <strong>November 15, 2025</strong> .</p>
        
      </div>
	  <section id="submission" class="section container">
  <h2>Submission</h2>

  <h3>Submission Format</h3>
  <p>
    <strong>Option 1 — Preprint/Publication Submission:</strong>  
    Submit a PDF of your publication or preprint. This option is straightforward and ideal for authors without copyright restrictions or concerns about sharing their paper/preprint on another platform.
  </p>

  <p>
    <strong>Option 2 — Abstract Submission:</strong>  
    For abstract submission, we recommend 1 to 3 pages, with unlimited pages for references and figures, but longer submissions are also accepted. You may use any template of your choice.
  </p>

  <h3>Submission Portal</h3>
  <p>
    Enter your submission using the following Google Form:  
    <a class="submission-link" href="https://forms.gle/JhqTDhS5PsM6CQ4P6" target="_blank">
      https://forms.gle/JhqTDhS5PsM6CQ4P6
    </a>
  </p>
</section>
    </section>

 <!-- Important Dates Section -->
<section id="dates" class="section alt">
  <div class="container">
    <h2>Important Dates</h2>
    <p>
      We will have two submission rounds. To take advantage of NetSciX’s early bird registration rate, please submit in Round 1.
      Decisions for Round 1 will be communicated by <strong>November 20, 2026</strong>.
    </p>

    <ul class="dates-list">
      <li><strong>November 1:</strong> Call for abstracts is released</li>
      <li><strong>November 15:</strong> Round 1 deadline</li>
      <li><strong>November 20:</strong> Round 1 acceptance notice</li>
      <li>
        <strong>November 30:</strong> Early bird registration deadline
        (<a href="https://netscix2026.github.io/#register" target="_blank">NetSciX 2026 Registration</a>)
      </li>
      <li><strong>November 25:</strong> Round 2 deadline (dependent on the number of accepted papers from Round 1)</li>
      <li><strong>November 30:</strong> Round 2 acceptance notice</li>
    </ul>

    <p>
      Submissions will be evaluated for contributed talks based on their relevance to the satellite theme, originality, novelty, 
      and scientific quality. Notification of acceptance will be sent by November 20 and November 30, 2025.
      Upon acceptance, at least one author must register and attend the session to present the work.
    </p>

    <p>
      If you have any queries, please email us at 
      <a class="submission-link" href="mailto:fairnetsci@gmail.com">fairnetsci@gmail.com</a>.
    </p>
  </div>
</section>   

    <!-- Speakers -->
<section id="speakers" class="section alt">
  <div class="container">
    <h2>Speakers</h2>

    <div class="speaker-card">
      <img
        src="https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=61JYIhYAAAAJ&citpid=6"
        alt="Dr. Giulia De Pasquale"
        class="speaker-photo"
      />

      <div class="speaker-info">
        <h3>
          <a href="https://sites.google.com/view/giuliadepasquale/home-page" target="_blank">
            Dr. Giulia De Pasquale
          </a>
        </h3>
        <p><strong>TU Eindhoven</strong></p>
      </div>
    </div>

  </div>
</section>

    <!-- Schedule -->
    <section id="schedule" class="section alt">
  <div class="container">
    <h2>Program</h2>
    <p>
  <strong>Timetable:</strong> 1:15 – 2:45 PM (90 minutes = 15 + 30 + 20 + 20 + 5) <br />
  <strong>Date:</strong> 19 Feb (Thu)
</p>

<h3>Algorithmic Fairness in Network Science</h3>

<div class="program-table-wrapper">
  <table class="program-table">
    <thead>
      <tr>
        <th>Time</th>
        <th>Type</th>
        <th>Speaker</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>1:15 – 1:30 PM</td>
        <td>Opening Remarks</td>
        <td>Dr. Akrati Saxena</td>
        <td>Algorithmic Fairness in Network Science</td>
      </tr>
      <tr>
        <td>1:30 – 2:00 PM</td>
        <td>Invited Talk</td>
        <td>Dr. Giulia De Pasquale</td>
        <td>Network Awareness Promotes Fairness in Recommender Systems</td>
      </tr>
      <tr>
        <td>2:00 – 2:20 PM</td>
        <td>Contributed</td>
        <td>Georgios Panayiotou</td>
        <td>
          MOUFLON: Multi-group Modularity-based Fairness-aware Community Detection
        </td>
      </tr>
      <tr>
        <td>2:20 – 2:40 PM</td>
        <td>Contributed</td>
        <td>Yasaman Asgari</td>
        <td>
          Beyond One-Hop Neighbourhoods in Social Perception
        </td>
      </tr>
      <tr>
        <td>2:40 – 2:45 PM</td>
        <td>Closing Remarks</td>
        <td>Dr. Akrati Saxena</td>
        <td></td>
      </tr>
    </tbody>
  </table>
  </div>
  </div>

	  <!--
      <div class="schedule">
        <div class="schedule-row">
          <time>09:00</time>
          <div class="sched-item">
            <h4>Registration & Coffee</h4>
            <p class="muted">Lobby</p>
          </div>
        </div>

        <div class="schedule-row">
          <time>09:30</time>
          <div class="sched-item">
            <h4>Opening Remarks</h4>
            <p class="muted">Main Hall</p>
          </div>
        </div>

        <div class="schedule-row">
          <time>10:00</time>
          <div class="sched-item">
            <h4>Keynote</h4>
            <p class="muted">Speaker</p>
          </div>
        </div>-->
      </div>
    </section>

    <section id="organizers" class="section alt">
  <div class="container">
    <h2>Organizers</h2>

    <!-- Organizer 1 -->
    <div class="organizer-card">
      <img src="https://www.universiteitleiden.nl/binaries/content/gallery/ul2/portraits/science/s/akrati-saxena.jpg/akrati-saxena.jpg/d200x250" alt="Dr. Akrati Saxena" class="organizer-photo" />

      <div class="organizer-info">
        <h3>Dr. Akrati Saxena</h3>
        <p>
          Dr. Akrati Saxena is an assistant professor at <a href="https://liacs.leidenuniv.nl/" target="_blank"><b>LIACS</b></a>, the computer science and AI institute of the <b>Faculty of Science of Leiden University</b>.  
          She leads the <a href="https://alfa.liacs.nl/" target="_blank"><b>AlFa</b></a> <b>(Algorithmic Fairness)</b> research group, which develops fairness-aware heuristic, approximation, machine learning, and deep learning-based
		  methods for complex network data. Her research interest lies at the intersection of Social Network Analysis, Complex Networks, Computational Social Science, Data Science, 
		  and Algorithmic Fairness. Her current work focuses on understanding inequalities in complex networks and advancing fairness-aware algorithms in network and data science, 
		  including analyzing biases in existing systems, defining fairness constraints and evaluation metrics, and designing fair computational frameworks. In addition to her research, 
		  she serves on the Diversity Committee at LIACS, contributing to efforts that foster inclusion and equity within the academic community.

        </p>
      </div>
    </div>

    <!-- Organizer 2 -->
    <div class="organizer-card">
      <img src="https://www.universiteitleiden.nl/binaries/content/gallery/ul2/portraits/science/f/franktakes-square512.png/franktakes-square512.png/d200x250" alt="Dr. Second Organizer" class="organizer-photo" />

      <div class="organizer-info">
        <h3>Dr. Frank Takes</h3>
        <p>
          Dr. Frank Takes is an associate professor at <a href="https://liacs.leidenuniv.nl/" target="_blank"><b>LIACS</b></a>, the computer science and AI institute of the <b>Faculty of Science of Leiden University</b>.
		  His research interest is in network science, in particular, the development of algorithms for the analysis of large-scale (social) network data, with applications in science studies, economics, and computational social science. 
		  He is the head of the Leiden <a href="https://cns.liacs.nl/" target="_blank"><b>Computational Network Science</b></a> research group, academic co-director of the Dutch 
		  <b>PLANET-NL platform</b> for population-scale social network analysis, and board member of the <b>Dutch Network Science Society</b>.
		  Since 2022, he has been the director of education of the LIACS bachelor programmes Informatica (Computer Science) and 
		  Data Science & Artificial Intelligence, and a member of the institute's management team.
        </p>
      </div>
    </div>
  </div>
</section>
<!-- Volunteers -->
<section id="volunteers" class="section container">
  <div class="container">
    <h2>Volunteers</h2>
    <ul class="volunteer-list">
  <li class="volunteer-item">
    <img
      src="https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=JRbLhuYAAAAJ&citpid=8"
      alt="Kirtidev Mohapatra"
      class="volunteer-photo"
    />
    <div class="volunteer-info">
      <strong>Kirtidev Mohapatra</strong><br />
      <span>IIT Bhilai, India</span>
    </div>
  </li>
</ul>
  </div>
</section>  
  <footer class="site-footer">
    <div class="container">
      <p>© FairNetSci 2026. All rights reserved.</p>
      
    </div>
  </footer>

  <!-- Small JS: smooth scroll, active nav, mobile menu -->
  <script>
    
    document.getElementById('year').textContent = new Date().getFullYear();

   
    (function () {
      const links = document.querySelectorAll('a[href^="#"]');
      for (const l of links) {
        l.addEventListener('click', function (e) {
          const targetId = l.getAttribute('href').slice(1);
          const target = document.getElementById(targetId);
          if (target) {
            e.preventDefault();
            const top = target.getBoundingClientRect().top + window.pageYOffset - 72; // header offset
            window.scrollTo({ top, behavior: 'smooth' });
            
            if (window.innerWidth < 900) {
              document.getElementById('site-nav').classList.remove('open');
            }
          }
        });
      }
    })();

    
    (function () {
      const sections = document.querySelectorAll('main section[id]');
      const navLinks = document.querySelectorAll('#site-nav a');
      function onScroll() {
        const fromTop = window.scrollY + 80;
        let current = null;
        sections.forEach((sec) => {
          if (sec.offsetTop <= fromTop) current = sec;
        });
        navLinks.forEach((a) => a.classList.remove('active'));
        if (current) {
          const id = current.getAttribute('id');
          const link = document.querySelector('#site-nav a[href="#' + id + '"]');
          if (link) link.classList.add('active');
        }
      }
      onScroll();
      window.addEventListener('scroll', onScroll, { passive: true });
    })();

   
    document.getElementById('menu-toggle').addEventListener('click', function () {
      document.getElementById('site-nav').classList.toggle('open');
    });

    
    const prefersReduced = window.matchMedia('(prefers-reduced-motion: reduce)').matches;
    if (prefersReduced) {
      document.documentElement.style.scrollBehavior = 'auto';
    }
	window.addEventListener('scroll', function() {
  const header = document.querySelector('.site-header');
  if (window.scrollY > 10) header.classList.add('scrolled');
  else header.classList.remove('scrolled');
});

document.addEventListener("click", function (e) {
  const isButton = e.target.matches(".dropbtn");
  const dropdown = document.querySelector(".dropdown");

  if (isButton) {
    e.preventDefault();
    dropdown.classList.toggle("open");
  } else {
    
    dropdown.classList.remove("open");
  }
});
  </script>
</body>
</html>
